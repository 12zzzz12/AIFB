#!/usr/bin/env python
# coding: utf-8

# **심화도전2**
# ### **Breast cancer wisconsin 데이터를 이용한 <span style="color:darkgreen">AI분류</span> 문제**
# ---

# #### 암세포의 형태 데이터를 이용하여 암 진단 판정을 악성과 양성으로 분류하는 AI문제입니다. 
# #### AI코딩 단계에 따라 주어지는 문제를 읽고 답안을 작성하세요.
# #### ( Breast cancer wisconsin 데이터 : sklearn 내장 연습용 데이터셋 사용)
# 
#  - 데이터 : 분류(카테고리)
#  - 모델 : KNN(머신러닝 모델 비교 분석), DeepLearning
#  - 주요 전처리 : 분석 Column 추가, 표준화(standardization)
#  - 주요 학습 내용 : 이중 분류 모델 생성(binary 분류, input, output 처리, 손실함수 등), 머신러닝 모델 비교학습(리스트 활용)
# ---
# 
# **아래 측정값들을, 평균(mean), 표준오차(error), 제일 큰 값 3개의 평균(worst)으로 나타낸다. 예를 들어 radius는 mean radius, radius error, worst radius 3개 컬럼으로 나타난다.**<br>
# 
# - radius : 암세포의 반지름
# - texture : 질감
# - perimeter : 둘레
# - area : 면적
# - smoothness : 매끄러움
# - concavity : 오목함
# - concave points : 오목한 곳의 수
# - symmetry : 대칭성
# - fractal dimension : 프렉탈 차원
# - class : 라벨(y변수) 데이터로 세포의 양성/악성 여부를 binary로 표기한 데이터
#     * 0 : malignant : 악성
#     * 1 : benign : 양성
# 

# ---
# > **<span style="color:red">다음 문항을 풀기 전에 </span>아래 코드를 실행하시오.**<br>
# > **sklearn에서 제공하는 load_breast_cacncer에 대한 데이터를 불러올 예정입니다. <span style="color:darkgreen"></span>**<br>
# > ** 해당 형태로 불러온 데이터는 AIDU 환경변수와 상관없이 사용할수 있습니다.<br>
# > 분석할 feautre 데이터는 x 변수에, 라벨은 y변수에 저장 되게 됩니다.(사전 x,y 데이터 분리 실행)
# > y변수는 상기 서술된 컬럼 중 class 항목입니다.
# 
# 
# ---
# 
# 

# In[1]:



from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()
x = cancer.data # 인풋으로 사용할 데이터
y = cancer.target # 아웃풋, target으로 사용할 데이터
col_names = cancer.feature_names # 인풋으로 사용할 데이터의 컬럼별 이름들
target_names = cancer.target_names # 아웃풋, target으로 사용할 데이터의 클래스 이름


# ### **Q1. pandas를 pd로 alias하여 사용할 수 있도록 불러오는 코드를 작성하고 실행하시기 바랍니다.**
# ---

# In[2]:


# 여기에 답안코드를 작성하세요

import pandas as pd


# ### **Q2.Matplotlib의 pyplot을 plt로 alias하여 사용할 수 있도록 불러오는 코드를 작성하고 실행하시기 바랍니다.**
# ---

# In[3]:


# 여기에 답안코드를 작성하세요
import matplotlib.pyplot as plt


# ### **Q3. 인풋데이터(x)와 인풋데이터 컬럼명(col_names)를 이용하여 인풋데이터의 dataframe을 제작하시기 바랍니다.**
# * **
# - 데이터 프레임의 변수 명은 bcc 로 한다.
# ---

# In[5]:


# 여기에 답안코드를 작성하세요

bcc = pd.DataFrame(x, columns=col_names)
print(bcc)
print(y)


# ### **Q4. 데이터를 트레이닝셋 / 테스트셋으로 분할하시기 바랍니다.**
# * **
# - bcc와, y를 이용한다. ( x를 사용해도 좋지만, 이후 문제를 위해 bcc를 이용한다.)
# - train : test = 8.5 : 1.5
# - y의 클래스가 골고루 분할되도록 stratify하게 분할한다.
# - 변수명 규칙은 다음과 같다.
#     * x_train, y_train
#     * x_test, y_test
# - random state, seed 등은 2021로 설정한다.
# ---

# In[6]:


# 여기에 답안코드를 작성하세요
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(bcc, y, test_size=0.15, stratify=y, random_state=2021)


# ### **Q5. 트레이닝 데이터를 트레이닝셋 / 벨리데이션셋으로 분할하시기 바랍니다.**
# * **
# - x_train, y_train을 이용한다.
# - train : validation = 7 : 3
# - y_train의 클래스가 골고루 분할되도록 stratify하게 분할한다.
# - 변수명 규칙은 다음과 같다.
#     * x_train, y_train
#     * y_valid, y_valid
# - random state, seed 등은 2021로 설정한다.
# ---

# In[7]:


# 여기에 답안코드를 작성하세요
x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.3, stratify=y_train, random_state=2021)


# ### **Q6. x_train, x_valid, x_test의 인덱스를 초기화 하시기 바랍니다.**
# * **
# - 현재 x들은 전부 dataframe이고, 원본 bcc의 인덱스를 그대로 가지고 있다.
# - 맨 첫번째 row부터 순서대로 인덱스를 갖도록 한다
# - 인덱스는 정수 인덱스이며, 0부터 시작한다.
# ---

# In[10]:


# 여기에 답안코드를 작성하세요
x_train.reset_index(drop=True)
x_test.reset_index(drop=True)
x_valid.reset_index(drop=True)


# ### **Q7. x_train, x_valid, x_test의 모든 컬럼을 각각 표준화(standardization) 스케일링 하시기 바랍니다.**
# * **
# - **모든 전처리 규칙은 트레이닝셋으로 부터 선정한다.**
# - 스케일링한 x들은 각각 아래의 변수에 따로 선언해둔다.
#     * x_train_sc
#     * x_valid_sc
#     * x_test_sc
# ---

# In[15]:


# 여기에 답안코드를 작성하세요
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()

sc.fit(x_train)
sc.fit(x_valid)
sc.fit(x_test)

x_train_sc = sc.transform(x_train)
x_valid_sc = sc.transform(x_valid)
x_test_sc = sc.transform(x_test)


# ### **Q8. KNN 모델들을 학습시키시기 바랍니다.**
# * **
# - 트레이닝 셋 (x_train_sc, y_train)을 이용하여 학습시킨다.
# - KNN의 이웃수(k)를 2부터 15까지 늘려가며 총 14개의 모델을 학습시킨다.
# - 학습시킨 트리들은 리스트를 만들어 knns 변수에 담아둔다.
# - y를 예측할 경우, 이웃들의 거리값은 반영하지 않는다.(weights 파라미터는 uniform을 사용한다.)
# - 각 모델을 knns 라는 list에 순차적으로 저장하시기 바랍니ㅣ다.
# ---

# In[18]:


# 여기에 답안코드를 작성하세요
from sklearn.neighbors import KNeighborsClassifier

knns = []
for i in range(2,16):
    classifier = KNeighborsClassifier(n_neighbors = i, weights = 'uniform')
    knns.append(classifier.fit(x_train_sc, y_train))
    
print(knns)


# ### **Q9. KNN 모델들의 성능을 리스트에 담아 accs에 선언하시기 바랍니다.**
# * **
# - k가 2인 knn모델부터 순서대로 평가하여 리스트에 담는다.
# - 벨리데이션 셋 위에서 성능을 평가한다. (x는 스케일링 된 값이어야 한다.)
# - 성능지표로는 accuracy를 사용한다.
# ---

# In[21]:


# 여기에 답안코드를 작성하세요
accs = []

for c in knns:
    accs.append(c.score(x_valid_sc, y_valid))
print(accs)


# ### **Q10. KNN모델들의 k(이웃수)에 따른 accuracy를 시각화 하고, 가장 성능이 좋은 k 값을 선택하시기 바랍니다.**
# * **
# - 위의 Q9에서 제작한 리스트 accs를 이용한다.
# - line plot 이나 scatter plot을 이용한다.
# - 동일 성능의 k가 여러개라면, 가장 작은 k를 선택한다.
# ---

# In[26]:


# 여기에 답안코드를 작성하세요
plt.plot(accs)

index = 0
best_k = 0
m = max(accs)
for i, acc in enumerate(accs):
    if m == acc:
        best_k = i
        break

print(accs[best_k])


# ### **Q11. 선택된 KNN모델의 테스트셋 위에서의 accuracy를 출력하시기 바랍니다.**
# * **
# - 성능 확인 시 입력데이터는 스케일링 된 데이터인 x_test_sc를 사용해야 한다.
# ---

# In[33]:


# 여기에 답안코드를 작성하세요
acct = []

for c in knns:
    acct.append(c.score(x_test_sc, y_test))
#print(acct)
index = 0
best = 0
m = max(acct)
for i, acc in enumerate(acct):
    if m == acc:
        best = i
        break

print(accs[best],best)


# ### **Q12. 해당 모델의 classificaiton report를 출력하고, malignant의 precision 값을 출력하시오**
# ---
#   - 테스트셋 위의 성능 평가를 바탕으로 문제를 푼다.
#   - 성능 확인 시 입력데이터는 스케일링 된 데이터인 x_test_sc를 사용해야 한다.
# ---

# In[35]:


from sklearn.metrics import classification_report

#y_pred = model.predict(X_test_features)
print(classification_report(y_test, knns[best].predict(x_test_sc), target_names=['malignant', 'precision']))


# ### **Q13. Q8에서 Q11 까지의 학습 과정을 scaling 되지 않은 원본데이터로 학습하여 별도의 모델을 만드시기 바랍니다.**
# * **
# - 해당 모델의 classificaiton report를 출력하고, malignant의 precision 값을 출력하시오
#     - 테스트셋 위의 성능 평가를 바탕으로 문제를 푼다.
#     - 성능 확인 시 입력데이터는 스케일링 하지 않은 데이터인 x_valid를 사용해야 한다.
# ---

# In[37]:


# 여기에 답안코드를 작성하세요
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

knns = []
for i in range(2,16):
    classifier = KNeighborsClassifier(n_neighbors = i, weights = 'uniform')
    knns.append(classifier.fit(x_train, y_train))
print(knns)

accs = []
for c in knns:
    accs.append(c.score(x_test, y_test))
print(accs)

index = 0
best_k = 0
m = max(accs)
for i, acc in enumerate(accs):
    if m == acc:
        best_k = i
        break

print(accs[best_k], best_k)

#y_pred = model.predict(X_test_features)
print(classification_report(y_valid, knns[best_k].predict(x_valid), target_names=['malignant', 'precision']))


# ### **Q14. 스케일링하지 않은 데이터의 예측 모델 성능과, 스케일링한 데이터의 예측모델 성능을 출력하여 비교하시기 바랍니다.**
# * **
# - 기존 만든 best_knn 모델의 score를 사용하여 성능을 출력할 것
# - 스케일링한 학습 모델은 데이터 : x_test_sc 활용
# - 스케일링하지 않은 모델은 데이터 x_test 활용
# ---

# In[42]:


# 여기에 답안코드를 작성하세요
print(knns[best].score(x_test_sc, y_test))
print(knns[best].score(x_test, y_test))


# > **<span style="color:red">다음 문항을 풀기 전에 </span>아래 코드를 실행하세요.**
# >

# In[45]:


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint


# ### **Q16. 아래 조건에 맞추어 뉴럴네트워크 모델을 학습시키시기 바랍니다**
# * **
# - Tensorflow framework를 사용한다.
# - 히든레이어는 아래와 같은 규칙에 맞추어 구성합니다.
#     * 3개 이상의 fully connected layer를 사용할 것
#     * Drop out과 batchnormalization을 각각 한번 이상 사용한다.
# - Early stopping을 이용하여, validation loss가 10번 이상 개선되지 않으면 학습을 중단 시키고, 가장 성능이 좋았을 때의 가중치를 복구한다.
# - 학습과정의 로그(loss, accuracy)를 history에 선언하여 남긴다.
# - y를 별도로 원핫인코딩 하지 않고 분류모델을 학습시킬 수 있도록 한다.
# - 0,1로 구분된 binary 분류모델에 맞는 loss function인 binary_crossentropy를 사용하도록 한다.
# - epochs는 2000번을 지정한다.
# ---

# In[50]:


# 여기에 답안코드를 작성하세요
model = Sequential()
model.add(Dense(256, activation='relu', input_shape=x_train.shape[1:]))
model.add(Dropout(0.1))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(64, activation='relu'))
model.add(BatchNormalization())
model.add(Dense(32, activation='relu'))
model.add(BatchNormalization())
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])

mc = ModelCheckpoint('best_modelsss22.h5', monitor='val_loss', save_best_only=True)
es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=10)
history = model.fit(x_train, y_train, batch_size=32, epochs=2000, validation_data=(x_valid,y_valid), callbacks=[mc,es])


# ### **Q17. 다음 조건에 맞추어 뉴럴네트워크의 학습 로그를 시각화 하시오.**
# * **
# - 필요한 라이브러리가 있다면 따로 불러온다.
# - epochs에 따른 accuracy의 변화를 시각화 한다.
# - train accuracy와 validation accuracy를 전부 시각화하고, 구별가능해야 한다.
# - 그래프의 타이틀은 'Accuracy'로 표시한다.
# - x축에는 'epochs'라고 표시하고 y축에는 'accuracy'라고 표시한다.
# - 위에서 학습한 머신러닝 모델과 성능을 비교해보시오. 
# ---

# In[51]:


# 여기에 답안코드를 작성하세요
plt.plot(history.history['acc'], label='train acc')
plt.plot(history.history['val_acc'], label='validation acc')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracty')
plt.legend()
plt.show()


# In[ ]:




